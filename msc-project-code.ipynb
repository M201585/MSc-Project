{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nfrom scipy import sparse\nfrom tqdm import tqdm\n\nfrom sklearn.model_selection import GroupShuffleSplit\nfrom bisect import bisect\nfrom sklearn.metrics import mean_squared_error\n\nfrom transformers import AutoConfig\nfrom transformers import AutoTokenizer, AutoModel\n\nimport torch.nn as nn\nimport copy\n\nfrom tqdm import tqdm\nimport sys, os\nfrom transformers import DistilBertModel, DistilBertTokenizer\nimport torch.nn.functional as F\nimport torch.nn as nn\nimport torch\n\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import RobertaTokenizer\n\nimport time\n\nimport matplotlib.pyplot as plt\n","metadata":{"papermill":{"duration":0.122804,"end_time":"2022-05-12T10:15:14.04297","exception":false,"start_time":"2022-05-12T10:15:13.920166","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-09-14T11:43:34.359866Z","iopub.execute_input":"2022-09-14T11:43:34.360820Z","iopub.status.idle":"2022-09-14T11:43:34.369152Z","shell.execute_reply.started":"2022-09-14T11:43:34.360761Z","shell.execute_reply":"2022-09-14T11:43:34.368054Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"pd.options.display.width = 180\npd.options.display.max_colwidth = 120\n\nbert = AutoModel.from_pretrained(\"microsoft/codebert-base\")\ndata_dir = Path('../input/ai4code')","metadata":{"execution":{"iopub.status.busy":"2022-09-14T11:20:25.200793Z","iopub.execute_input":"2022-09-14T11:20:25.201257Z","iopub.status.idle":"2022-09-14T11:20:27.825172Z","shell.execute_reply.started":"2022-09-14T11:20:25.201223Z","shell.execute_reply":"2022-09-14T11:20:27.824058Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#Read dataset\ndef read_notebook(path):\n    return (\n        pd.read_json(\n            path,\n            dtype={'cell_type': 'category', 'source': 'str'})\n        .assign(id=path.stem)\n        .rename_axis('cell_id'))","metadata":{"execution":{"iopub.status.busy":"2022-09-14T11:20:27.826930Z","iopub.execute_input":"2022-09-14T11:20:27.827342Z","iopub.status.idle":"2022-09-14T11:20:27.835686Z","shell.execute_reply.started":"2022-09-14T11:20:27.827299Z","shell.execute_reply":"2022-09-14T11:20:27.834578Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"#Get the kendall tau corelation values\ndef count_inversions(a):\n    inversions = 0\n    sorted_so_far = []\n    for i, u in enumerate(a):\n        j = bisect(sorted_so_far, u)\n        inversions += i - j\n        sorted_so_far.insert(j, u)\n    return inversions\n\n\ndef kendall_tau(ground_truth, predictions):\n    total_inversions = 0\n    total_2max = 0  # twice the maximum possible inversions across all instances\n    for gt, pred in zip(ground_truth, predictions):\n        ranks = [gt.index(x) for x in pred]  # rank predicted order in terms of ground truth\n        total_inversions += count_inversions(ranks)\n        n = len(gt)\n        total_2max += n * (n - 1)\n    return 1 - 4 * total_inversions / total_2max","metadata":{"execution":{"iopub.status.busy":"2022-09-14T11:20:27.837474Z","iopub.execute_input":"2022-09-14T11:20:27.838275Z","iopub.status.idle":"2022-09-14T11:20:27.849323Z","shell.execute_reply.started":"2022-09-14T11:20:27.838230Z","shell.execute_reply":"2022-09-14T11:20:27.848234Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"#Get the different intermediate blocks\ndef deletelayers(model, num_layers_to_keep,n):\n    oldModuleList = model.encoder.layer\n    newModuleList = nn.ModuleList()\n    \n    for j in range(0, num_layers_to_keep):\n        newModuleList.append(oldModuleList[j])\n        \n    for i in range(num_layers_to_keep,11):\n        newModuleList.append(oldModuleList[i].attention)\n        \n    copyofModel = copy.deepcopy(model)\n    copyofModel.encoder.layer = newModuleList\n    \n    return copyofModel","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Get the different self-attention blocks\ndef deletelayers_attention(model, num_layers_to_keep,n):\n    oldModuleList = model.encoder.layer\n    newModuleList = nn.ModuleList()\n    \n    #for j in range(0, num_layers_to_keep):\n        #newModuleList.append(oldModuleList[j])\n        \n    for i in range(12):\n        newModuleList.append(oldModuleList[i])\n        if i > num_layers_to_keep:\n            newModuleList.append(oldModuleList[i].intermediate)\n            newModuleList.append(oldModuleList[i].output)\n            \n        \n    copyofModel = copy.deepcopy(model)\n    copyofModel.encoder.layer = newModuleList\n    \n    return copyofModel","metadata":{"execution":{"iopub.status.busy":"2022-09-14T13:24:00.638744Z","iopub.execute_input":"2022-09-14T13:24:00.639227Z","iopub.status.idle":"2022-09-14T13:24:00.652653Z","shell.execute_reply.started":"2022-09-14T13:24:00.639188Z","shell.execute_reply":"2022-09-14T13:24:00.651476Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"#Get the different encoder layers\ndef deletelayers_layer(model, num_layers_to_keep,n):\n    oldModuleList = model.encoder.layer\n    newModuleList = nn.ModuleList()\n    \n    for j in range(0, num_layers_to_keep):\n        newModuleList.append(oldModuleList[j])\n        \n    copyofModel = copy.deepcopy(model)\n    copyofModel.encoder.layer = newModuleList\n    \n    return copyofModel","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Get the different combination of intermediate blocks and encoder layers\ndef deletelayers_layer_attention(model, num_layers_to_keep,n):\n    oldModuleList = model.encoder.layer\n    newModuleList = nn.ModuleList()\n    \n    for j in range(0, num_layers_to_keep):\n        newModuleList.append(oldModuleList[j])\n        \n    for i in range(num_layers_to_keep,n):\n        newModuleList.append(oldModuleList[i].attention)\n        \n    copyofModel = copy.deepcopy(model)\n    copyofModel.encoder.layer = newModuleList\n    \n    return copyofModel","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Build a model\nclass MarkdownModel(nn.Module):\n    def __init__(self,deletemodel,num_intermediate_to_keep, num_layer):\n        super(MarkdownModel, self).__init__()\n        #self.distill_bert = DistilBertModel.from_pretrained('../input/huggingface-bert-variants/distilbert-base-uncased/distilbert-base-uncased')\n        self.num_intermediate_to_keep = num_intermediate_to_keep \n        self.num_layer = num_layer\n        self.deletemodel = deletemodel\n        self.distill_bert = self.deletemodel(bert, self.num_intermediate_to_keep, self.num_layer)\n        self.top1 = nn.Linear(768, 64)\n        self.top2 = nn.Linear(64, 1)\n\n        self.dropout1 = torch.nn.Dropout(p=0.2)\n        self.dropout2 = torch.nn.Dropout(p=0.2)\n        \n    def forward(self, ids, mask):\n        x = self.distill_bert(ids, mask)[0][:, 0, :]\n        x = self.dropout1(x)\n        x0 = self.top1(x)\n        x = self.dropout2(x0)\n        x = self.top2(x)\n        x = torch.sigmoid(x)\n        return x","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Customize a dataset\nclass MarkdownDataset(Dataset):\n    \n    def __init__(self, df, max_len):\n        super().__init__()\n        self.df = df.reset_index(drop=True)\n        self.max_len = max_len\n        #self.tokenizer = DistilBertTokenizer.from_pretrained('../input/huggingface-bert-variants/distilbert-base-uncased/distilbert-base-uncased', do_lower_case=True)\n        self.tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\", do_lower_case=False)\n\n    def __getitem__(self, index):\n        row = self.df.iloc[index]\n        \n        inputs = self.tokenizer.encode_plus(\n            row.source,\n            None,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding=\"max_length\",\n            return_token_type_ids=True,\n            truncation=True\n        )\n        ids = torch.LongTensor(inputs['input_ids'])\n        mask = torch.LongTensor(inputs['attention_mask'])\n\n        return ids, mask, torch.FloatTensor([row.pct_rank])\n\n    def __len__(self):\n        return self.df.shape[0]\n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Get the best learning rate\ndef adjust_lr(optimizer, epoch):\n    if epoch < 1:\n        lr = 5e-5\n    elif epoch < 2:\n        lr = 1e-3\n    elif epoch < 5:\n        lr = 1e-4\n    else:\n        lr = 1e-5\n\n    for p in optimizer.param_groups:\n        p['lr'] = lr\n    return lr\n    \ndef get_optimizer(net):\n    optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr=3e-4, betas=(0.9, 0.999),\n                                 eps=1e-08)\n    return optimizer\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Train and test data\ndef read_data(data):\n    return tuple(d.cuda() for d in data[:-1]), data[-1].cuda()\n\n\ndef validate(model, val_loader):\n    model.eval()\n    \n    tbar = tqdm(val_loader, file=sys.stdout)\n    \n    preds = []\n    labels = []\n\n    with torch.no_grad():\n        for idx, data in enumerate(tbar):\n            inputs, target = read_data(data)\n            #print(inputs, target)\n\n            pred = model(inputs[0], inputs[1])\n\n            preds.append(pred.detach().cpu().numpy().ravel())\n            labels.append(target.detach().cpu().numpy().ravel())\n    \n    return np.concatenate(labels), np.concatenate(preds)\n\ndef train(model, train_loader, val_loader, epochs):\n    np.random.seed(0)\n    \n    optimizer = get_optimizer(model)\n\n    criterion = torch.nn.MSELoss()\n    \n    for e in range(epochs):\n        start = 0\n        start = time.time()\n        model.train()\n        tbar = tqdm(train_loader, file=sys.stdout)\n        \n        lr = adjust_lr(optimizer, e)\n        \n        loss_list = []\n        preds = []\n        labels = []\n\n        for idx, data in enumerate(tbar):\n            inputs, target = read_data(data)\n\n            optimizer.zero_grad()\n            pred = model(inputs[0], inputs[1])\n\n            loss = criterion(pred, target)\n            loss.backward()\n            optimizer.step()\n            \n            loss_list.append(loss.detach().cpu().item())\n            preds.append(pred.detach().cpu().numpy().ravel())\n            labels.append(target.detach().cpu().numpy().ravel())\n            \n            avg_loss = np.round(np.mean(loss_list), 4)\n\n            tbar.set_description(f\"Epoch {e+1} Loss: {avg_loss} lr: {lr}\")\n        \n        y_train, y_pred_train = validate(model, train_loader)\n        y_val, y_pred = validate(model, val_loader)\n        \n        end = 0\n        end = time.time()\n        print(\"Training MSE:\", np.round(mean_squared_error(y_train, y_pred_train), 4))    \n        print(\"Validation MSE:\", np.round(mean_squared_error(y_val, y_pred), 4))\n        print('Running time:', end - start)\n        print()\n    return model, y_pred, np.round(mean_squared_error(y_train, y_pred_train), 4), np.round(mean_squared_error(y_val, y_pred), 4),end - start","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Get the training data\n\nNUM_TRAIN = 1000\n\npaths_train = list((data_dir / 'train').glob('*.json'))[:NUM_TRAIN]\nnotebooks_train = [\n    read_notebook(path) for path in tqdm(paths_train, desc='Train NBs')\n]\ndf = (\n    pd.concat(notebooks_train)\n    .set_index('id', append=True)\n    .swaplevel()\n    .sort_index(level='id', sort_remaining=False)\n)\n","metadata":{"papermill":{"duration":82.291505,"end_time":"2022-05-12T10:16:36.365197","exception":false,"start_time":"2022-05-12T10:15:14.073692","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-09-14T11:20:27.853667Z","iopub.execute_input":"2022-09-14T11:20:27.854019Z","iopub.status.idle":"2022-09-14T11:20:34.776453Z","shell.execute_reply.started":"2022-09-14T11:20:27.853994Z","shell.execute_reply":"2022-09-14T11:20:34.775502Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"Train NBs:  38%|███▊      | 381/1000 [00:34<00:56, 11.05it/s] \nTrain NBs: 100%|██████████| 1000/1000 [00:05<00:00, 172.27it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"#Combine all of csv into one table\ndf_orders = pd.read_csv(\n    data_dir / 'train_orders.csv',\n    index_col='id',\n    squeeze=True,\n).str.split()  # Split the string representation of cell_ids into a list\n\ndef get_ranks(base, derived):\n    return [base.index(d) for d in derived]\n\n#nb\n\ndf_orders_ = df_orders.to_frame().join(\n    df.reset_index('cell_id').groupby('id')['cell_id'].apply(list),\n    how='right',\n)\n\nranks = {}\nfor id_, cell_order, cell_id in df_orders_.itertuples():\n    ranks[id_] = {'cell_id': cell_id, 'rank': get_ranks(cell_order, cell_id)}\n\ndf_ranks = (\n    pd.DataFrame\n    .from_dict(ranks, orient='index')\n    .rename_axis('id')\n    .apply(pd.Series.explode)\n    .set_index('cell_id', append=True)\n)\n\n#df_ranks\n\ndf_ancestors = pd.read_csv(data_dir / 'train_ancestors.csv', index_col='id')\n#df_ancestors\n\ndf = df.reset_index().merge(df_ranks, on=[\"id\", \"cell_id\"]).merge(df_ancestors, on=[\"id\"])","metadata":{"execution":{"iopub.status.busy":"2022-09-14T11:20:34.777945Z","iopub.execute_input":"2022-09-14T11:20:34.779141Z","iopub.status.idle":"2022-09-14T11:20:37.470662Z","shell.execute_reply.started":"2022-09-14T11:20:34.779091Z","shell.execute_reply":"2022-09-14T11:20:37.469622Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"#Normalize the rangking for each snippet of code\ndf[\"pct_rank\"] = df[\"rank\"] / df.groupby(\"id\")[\"cell_id\"].transform(\"count\")","metadata":{"execution":{"iopub.status.busy":"2022-09-14T11:20:37.472288Z","iopub.execute_input":"2022-09-14T11:20:37.472662Z","iopub.status.idle":"2022-09-14T11:20:37.490475Z","shell.execute_reply.started":"2022-09-14T11:20:37.472626Z","shell.execute_reply":"2022-09-14T11:20:37.489591Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"#Split the data into 2 sets\nNVALID = 1/3 \n\nsplitter = GroupShuffleSplit(n_splits=1, test_size=NVALID, random_state=0)\n\ntrain_ind, val_ind = next(splitter.split(df, groups=df[\"ancestor_id\"]))\n\ntrain_df = df.loc[train_ind].reset_index(drop=True)\nval_df = df.loc[val_ind].reset_index(drop=True)","metadata":{"papermill":{"duration":1.895199,"end_time":"2022-05-12T10:16:49.969199","exception":false,"start_time":"2022-05-12T10:16:48.074","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-09-14T11:20:37.492007Z","iopub.execute_input":"2022-09-14T11:20:37.492367Z","iopub.status.idle":"2022-09-14T11:20:37.550687Z","shell.execute_reply.started":"2022-09-14T11:20:37.492332Z","shell.execute_reply":"2022-09-14T11:20:37.549759Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"#Get the markdown data\ntrain_df_mark = train_df[train_df[\"cell_type\"] == \"markdown\"].reset_index(drop=True)\nval_df_mark = val_df[val_df[\"cell_type\"] == \"markdown\"].reset_index(drop=True)","metadata":{"papermill":{"duration":0.371916,"end_time":"2022-05-12T10:16:52.797271","exception":false,"start_time":"2022-05-12T10:16:52.425355","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-09-14T11:20:37.552040Z","iopub.execute_input":"2022-09-14T11:20:37.552401Z","iopub.status.idle":"2022-09-14T11:20:37.567830Z","shell.execute_reply.started":"2022-09-14T11:20:37.552366Z","shell.execute_reply":"2022-09-14T11:20:37.566971Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"#Get the size of modified networks\n# 1 attention block\nprint(7087872 - sum([2359296,3072,2359296,768,768,768]))\n# 1 intermediate block\nprint(sum([2359296,3072,2359296,768,768,768]))","metadata":{"execution":{"iopub.status.busy":"2022-09-14T11:20:37.569246Z","iopub.execute_input":"2022-09-14T11:20:37.569601Z","iopub.status.idle":"2022-09-14T11:20:37.576629Z","shell.execute_reply.started":"2022-09-14T11:20:37.569566Z","shell.execute_reply":"2022-09-14T11:20:37.575489Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"2363904\n4723968\n","output_type":"stream"}]},{"cell_type":"code","source":"#Get the parameters of modified networks with different encoder layers\nsize_l = []\nfor i in range(0, 13):\n    print(i, 'encoder layer: ', round((7087872 * i + 38999808) * 0.000001, 2))\n    size_l.append(round((7087872 * i + 38999808) * 0.000001, 2))\nsize_l","metadata":{"execution":{"iopub.status.busy":"2022-09-14T11:20:37.578359Z","iopub.execute_input":"2022-09-14T11:20:37.579580Z","iopub.status.idle":"2022-09-14T11:20:37.595133Z","shell.execute_reply.started":"2022-09-14T11:20:37.579546Z","shell.execute_reply":"2022-09-14T11:20:37.594138Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"0 encoder layer:  39.0\n1 encoder layer:  46.09\n2 encoder layer:  53.18\n3 encoder layer:  60.26\n4 encoder layer:  67.35\n5 encoder layer:  74.44\n6 encoder layer:  81.53\n7 encoder layer:  88.61\n8 encoder layer:  95.7\n9 encoder layer:  102.79\n10 encoder layer:  109.88\n11 encoder layer:  116.97\n12 encoder layer:  124.05\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"[39.0,\n 46.09,\n 53.18,\n 60.26,\n 67.35,\n 74.44,\n 81.53,\n 88.61,\n 95.7,\n 102.79,\n 109.88,\n 116.97,\n 124.05]"},"metadata":{}}]},{"cell_type":"code","source":"#Get the size of modified networks with different encoder layers\nsize_l_d = []\nfor i in range(13):\n    size_l_d.append(round(size_l[12] / size_l[i],2))\nsize_l_d","metadata":{"execution":{"iopub.status.busy":"2022-09-14T11:20:37.596942Z","iopub.execute_input":"2022-09-14T11:20:37.597300Z","iopub.status.idle":"2022-09-14T11:20:37.605602Z","shell.execute_reply.started":"2022-09-14T11:20:37.597269Z","shell.execute_reply":"2022-09-14T11:20:37.604540Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"[3.18, 2.69, 2.33, 2.06, 1.84, 1.67, 1.52, 1.4, 1.3, 1.21, 1.13, 1.06, 1.0]"},"metadata":{}}]},{"cell_type":"code","source":"#Get the parameters of modified networks with different intermediate blocks\nsize_i = []\nfor i in range(0, 13):\n    print(i, 'intermediate block: ', (7087872 - sum([2359296,3072,2359296,768,768,768])) * 12 + 38999808 +  (sum([2359296,3072,2359296,768,768,768])) * i)\n    size_i.append(round(((7087872 - sum([2359296,3072,2359296,768,768,768])) * 12 + 38999808 +  sum([2359296,3072,2359296,768,768,768]) * i) * 0.000001,2))\nsize_i","metadata":{"execution":{"iopub.status.busy":"2022-09-14T11:20:37.607223Z","iopub.execute_input":"2022-09-14T11:20:37.607619Z","iopub.status.idle":"2022-09-14T11:20:37.619939Z","shell.execute_reply.started":"2022-09-14T11:20:37.607586Z","shell.execute_reply":"2022-09-14T11:20:37.618866Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"0 intermediate block:  67366656\n1 intermediate block:  72090624\n2 intermediate block:  76814592\n3 intermediate block:  81538560\n4 intermediate block:  86262528\n5 intermediate block:  90986496\n6 intermediate block:  95710464\n7 intermediate block:  100434432\n8 intermediate block:  105158400\n9 intermediate block:  109882368\n10 intermediate block:  114606336\n11 intermediate block:  119330304\n12 intermediate block:  124054272\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"[67.37,\n 72.09,\n 76.81,\n 81.54,\n 86.26,\n 90.99,\n 95.71,\n 100.43,\n 105.16,\n 109.88,\n 114.61,\n 119.33,\n 124.05]"},"metadata":{}}]},{"cell_type":"code","source":"#Get the parameters of modified networks with different self-attention blocks\nsize_a = []\nfor i in range(0, 13):\n    print(i, 'self-attention block: ', sum([2359296,3072,2359296,768,768,768]) * 12 + 38999808 +  (7087872 - sum([2359296,3072,2359296,768,768,768])) * i)\n    size_a.append(round((sum([2359296,3072,2359296,768,768,768]) * 12 + 38999808 +  (7087872 - sum([2359296,3072,2359296,768,768,768])) * i) * 0.000001,2))\nsize_a","metadata":{"execution":{"iopub.status.busy":"2022-09-14T11:20:37.628300Z","iopub.execute_input":"2022-09-14T11:20:37.628621Z","iopub.status.idle":"2022-09-14T11:20:37.639179Z","shell.execute_reply.started":"2022-09-14T11:20:37.628596Z","shell.execute_reply":"2022-09-14T11:20:37.637891Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"0 self-attention block:  95687424\n1 self-attention block:  98051328\n2 self-attention block:  100415232\n3 self-attention block:  102779136\n4 self-attention block:  105143040\n5 self-attention block:  107506944\n6 self-attention block:  109870848\n7 self-attention block:  112234752\n8 self-attention block:  114598656\n9 self-attention block:  116962560\n10 self-attention block:  119326464\n11 self-attention block:  121690368\n12 self-attention block:  124054272\n","output_type":"stream"},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"[95.69,\n 98.05,\n 100.42,\n 102.78,\n 105.14,\n 107.51,\n 109.87,\n 112.23,\n 114.6,\n 116.96,\n 119.33,\n 121.69,\n 124.05]"},"metadata":{}}]},{"cell_type":"code","source":"#Get the size of modified networks with different self-attention blocks\nsize_a_d = []\nfor i in range(13):\n    size_a_d.append(round(size_a[12] / size_a[i],2))\nsize_a_d","metadata":{"execution":{"iopub.status.busy":"2022-09-14T11:20:37.640503Z","iopub.execute_input":"2022-09-14T11:20:37.641325Z","iopub.status.idle":"2022-09-14T11:20:37.649964Z","shell.execute_reply.started":"2022-09-14T11:20:37.641290Z","shell.execute_reply":"2022-09-14T11:20:37.648881Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"[1.3, 1.27, 1.24, 1.21, 1.18, 1.15, 1.13, 1.11, 1.08, 1.06, 1.04, 1.02, 1.0]"},"metadata":{}}]},{"cell_type":"code","source":"#Get dataloader\nMAX_LEN = 128\n\ntrain_ds = MarkdownDataset(train_df_mark, max_len=MAX_LEN)\nval_ds = MarkdownDataset(val_df_mark, max_len=MAX_LEN)\n\n\nBS = 32\nNW = 2\n\ntrain_loader = DataLoader(train_ds, batch_size=BS, shuffle=True, num_workers=NW,\n                          pin_memory=False, drop_last=True)\nval_loader = DataLoader(val_ds, batch_size=BS, shuffle=False, num_workers=NW,\n                          pin_memory=False, drop_last=False)","metadata":{"execution":{"iopub.status.busy":"2022-09-14T11:20:56.018309Z","iopub.execute_input":"2022-09-14T11:20:56.018712Z","iopub.status.idle":"2022-09-14T11:21:02.393380Z","shell.execute_reply.started":"2022-09-14T11:20:56.018678Z","shell.execute_reply":"2022-09-14T11:21:02.392334Z"},"trusted":true},"execution_count":36,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d00b640bc6f4add85d467cb7e7d0cf8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7b87d13457b4ebba963e5dbc1760380"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/150 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8677fedfe63d41f2bf394f0a1bbe3ff4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0714a7631eb74744ae73c11d7e9dad8a"}},"metadata":{}}]},{"cell_type":"code","source":"#0-8 intermediate blocks and 7 layers \ntrain_error_n = []\nvali_error_n = []\nkt_error_n = []\ntime_list_n = []\nfor num_layers_to_keep in range(8):\n    model = MarkdownModel(deletelayers_layer_attention, num_layers_to_keep, 8)\n    model = model.cuda()\n    model, y_pred, train_MSE, vali_MSE, time_n = train(model, train_loader, val_loader, epochs=1)\n    train_error_n.append(train_MSE)\n    vali_error_n.append(vali_MSE)\n    time_list_n.append(time_n)\n    torch.save(model, 'codebert-trained2.pkl')\n    val_df[\"pred\"] = val_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)\n    val_df.loc[val_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_pred\n    y_dummy = val_df.sort_values(\"pred\").groupby('id')['cell_id'].apply(list)\n    kt_error_n.append(kendall_tau(df_orders.loc[y_dummy.index], y_dummy))\nprint(kt_error_n)","metadata":{"execution":{"iopub.status.busy":"2022-09-14T11:21:57.277627Z","iopub.execute_input":"2022-09-14T11:21:57.278329Z","iopub.status.idle":"2022-09-14T11:34:57.684975Z","shell.execute_reply.started":"2022-09-14T11:21:57.278289Z","shell.execute_reply":"2022-09-14T11:34:57.683651Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Epoch 1 Loss: 0.0908 lr: 5e-05: 100%|██████████| 342/342 [00:43<00:00,  7.94it/s]\n100%|██████████| 342/342 [00:18<00:00, 18.08it/s]\n100%|██████████| 152/152 [00:06<00:00, 22.30it/s]\nTraining MSE: 0.0828\nValidation MSE: 0.0849\nRunning time: 68.82322716712952\n\nEpoch 1 Loss: 0.0798 lr: 5e-05: 100%|██████████| 342/342 [00:47<00:00,  7.21it/s]\n100%|██████████| 342/342 [00:20<00:00, 16.99it/s]\n100%|██████████| 152/152 [00:07<00:00, 20.52it/s]\nTraining MSE: 0.0649\nValidation MSE: 0.0732\nRunning time: 74.99281406402588\n\nEpoch 1 Loss: 0.0719 lr: 5e-05: 100%|██████████| 342/342 [00:53<00:00,  6.38it/s]\n100%|██████████| 342/342 [00:21<00:00, 15.97it/s]\n100%|██████████| 152/152 [00:08<00:00, 18.55it/s]\nTraining MSE: 0.0549\nValidation MSE: 0.068\nRunning time: 83.21712064743042\n\nEpoch 1 Loss: 0.061 lr: 5e-05: 100%|██████████| 342/342 [00:59<00:00,  5.79it/s] \n100%|██████████| 342/342 [00:22<00:00, 14.91it/s]\n100%|██████████| 152/152 [00:09<00:00, 16.14it/s]\nTraining MSE: 0.0426\nValidation MSE: 0.0671\nRunning time: 91.48689770698547\n\nEpoch 1 Loss: 0.0516 lr: 5e-05: 100%|██████████| 342/342 [01:05<00:00,  5.21it/s]\n100%|██████████| 342/342 [00:24<00:00, 13.74it/s]\n100%|██████████| 152/152 [00:09<00:00, 15.99it/s]\nTraining MSE: 0.0351\nValidation MSE: 0.0706\nRunning time: 100.00212812423706\n\nEpoch 1 Loss: 0.0438 lr: 5e-05: 100%|██████████| 342/342 [01:11<00:00,  4.81it/s]\n100%|██████████| 342/342 [00:26<00:00, 13.01it/s]\n100%|██████████| 152/152 [00:10<00:00, 14.47it/s]\nTraining MSE: 0.0265\nValidation MSE: 0.0701\nRunning time: 107.90730500221252\n\nEpoch 1 Loss: 0.0375 lr: 5e-05: 100%|██████████| 342/342 [01:17<00:00,  4.43it/s]\n100%|██████████| 342/342 [00:27<00:00, 12.29it/s]\n100%|██████████| 152/152 [00:11<00:00, 13.58it/s]\nTraining MSE: 0.0208\nValidation MSE: 0.0745\nRunning time: 116.2314829826355\n\nEpoch 1 Loss: 0.032 lr: 5e-05: 100%|██████████| 342/342 [01:23<00:00,  4.11it/s] \n100%|██████████| 342/342 [00:29<00:00, 11.53it/s]\n100%|██████████| 152/152 [00:12<00:00, 12.62it/s]\nTraining MSE: 0.0173\nValidation MSE: 0.0721\nRunning time: 124.97964882850647\n\n[0.6461492008534966, 0.6731510930391722, 0.6963565360924353, 0.7034220379242321, 0.7065179757639197, 0.7053625347236201, 0.7018720560409034, 0.6997342888200009]\n","output_type":"stream"}]},{"cell_type":"code","source":"#0-8 intermediate blocks and 6 layers \ntrain_error_n = []\nvali_error_n = []\nkt_error_7 = []\ntime_list_7 = []\nfor num_layers_to_keep in range(7):\n    model = MarkdownModel(deletelayers_layer_attention, num_layers_to_keep, 7)\n    model = model.cuda()\n    model, y_pred, train_MSE, vali_MSE, time_n = train(model, train_loader, val_loader, epochs=1)\n    train_error_n.append(train_MSE)\n    vali_error_n.append(vali_MSE)\n    time_list_7.append(time_n)\n    torch.save(model, 'codebert-trained2.pkl')\n    val_df[\"pred\"] = val_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)\n    val_df.loc[val_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_pred\n    y_dummy = val_df.sort_values(\"pred\").groupby('id')['cell_id'].apply(list)\n    kt_error_7.append(kendall_tau(df_orders.loc[y_dummy.index], y_dummy))\nprint(kt_error_7)","metadata":{"execution":{"iopub.status.busy":"2022-09-14T11:45:07.989878Z","iopub.execute_input":"2022-09-14T11:45:07.991002Z","iopub.status.idle":"2022-09-14T11:55:18.038512Z","shell.execute_reply.started":"2022-09-14T11:45:07.990960Z","shell.execute_reply":"2022-09-14T11:55:18.037152Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"Epoch 1 Loss: 0.0718 lr: 5e-05: 100%|██████████| 342/342 [00:37<00:00,  9.02it/s]\n100%|██████████| 342/342 [00:17<00:00, 19.26it/s]\n100%|██████████| 152/152 [00:06<00:00, 23.45it/s]\nTraining MSE: 0.0587\nValidation MSE: 0.0704\nRunning time: 62.16468954086304\n\nEpoch 1 Loss: 0.0485 lr: 5e-05: 100%|██████████| 342/342 [00:43<00:00,  7.84it/s]\n100%|██████████| 342/342 [00:19<00:00, 17.85it/s]\n100%|██████████| 152/152 [00:06<00:00, 22.32it/s]\nTraining MSE: 0.0323\nValidation MSE: 0.075\nRunning time: 69.62682175636292\n\nEpoch 1 Loss: 0.0298 lr: 5e-05: 100%|██████████| 342/342 [00:50<00:00,  6.83it/s]\n100%|██████████| 342/342 [00:19<00:00, 17.34it/s]\n100%|██████████| 152/152 [00:07<00:00, 19.18it/s]\nTraining MSE: 0.0193\nValidation MSE: 0.0826\nRunning time: 77.77152180671692\n\nEpoch 1 Loss: 0.023 lr: 5e-05: 100%|██████████| 342/342 [00:55<00:00,  6.20it/s] \n100%|██████████| 342/342 [00:21<00:00, 15.78it/s]\n100%|██████████| 152/152 [00:08<00:00, 18.59it/s]\nTraining MSE: 0.012\nValidation MSE: 0.0786\nRunning time: 85.08121395111084\n\nEpoch 1 Loss: 0.0216 lr: 5e-05: 100%|██████████| 342/342 [01:01<00:00,  5.59it/s]\n100%|██████████| 342/342 [00:23<00:00, 14.58it/s]\n100%|██████████| 152/152 [00:09<00:00, 16.37it/s]\nTraining MSE: 0.0112\nValidation MSE: 0.078\nRunning time: 93.93635725975037\n\nEpoch 1 Loss: 0.0191 lr: 5e-05: 100%|██████████| 342/342 [01:07<00:00,  5.08it/s]\n100%|██████████| 342/342 [00:24<00:00, 13.83it/s]\n100%|██████████| 152/152 [00:10<00:00, 15.05it/s]\nTraining MSE: 0.0102\nValidation MSE: 0.0798\nRunning time: 102.13635015487671\n\nEpoch 1 Loss: 0.0181 lr: 5e-05: 100%|██████████| 342/342 [01:12<00:00,  4.69it/s]\n100%|██████████| 342/342 [00:27<00:00, 12.63it/s]\n100%|██████████| 152/152 [00:10<00:00, 14.43it/s]\nTraining MSE: 0.0091\nValidation MSE: 0.0799\nRunning time: 110.47466778755188\n\n[0.6846934256612585, 0.69872378115061, 0.6961190064012239, 0.7030436007890817, 0.7047868271669552, 0.703639437980595, 0.7049720198075606]\n","output_type":"stream"}]},{"cell_type":"code","source":"#0-8 intermediate blocks and 5 layers \ntrain_error_n = []\nvali_error_n = []\nkt_error_6 = []\ntime_list_6 = []\nfor num_layers_to_keep in range(6):\n    model = MarkdownModel(deletelayers_layer_attention, num_layers_to_keep, 6)\n    model = model.cuda()\n    model, y_pred, train_MSE, vali_MSE, time_n = train(model, train_loader, val_loader, epochs=1)\n    train_error_n.append(train_MSE)\n    vali_error_n.append(vali_MSE)\n    time_list_6.append(time_n)\n    torch.save(model, 'codebert-trained2.pkl')\n    val_df[\"pred\"] = val_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)\n    val_df.loc[val_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_pred\n    y_dummy = val_df.sort_values(\"pred\").groupby('id')['cell_id'].apply(list)\n    kt_error_6.append(kendall_tau(df_orders.loc[y_dummy.index], y_dummy))\nprint(kt_error_6)","metadata":{"execution":{"iopub.status.busy":"2022-09-14T12:03:49.848023Z","iopub.execute_input":"2022-09-14T12:03:49.848399Z","iopub.status.idle":"2022-09-14T12:11:31.380011Z","shell.execute_reply.started":"2022-09-14T12:03:49.848364Z","shell.execute_reply":"2022-09-14T12:11:31.378700Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"Epoch 1 Loss: 0.0628 lr: 5e-05: 100%|██████████| 342/342 [00:34<00:00, 10.05it/s]\n100%|██████████| 342/342 [00:16<00:00, 20.85it/s]\n100%|██████████| 152/152 [00:05<00:00, 25.95it/s]\nTraining MSE: 0.0518\nValidation MSE: 0.0756\nRunning time: 56.323400259017944\n\nEpoch 1 Loss: 0.028 lr: 5e-05: 100%|██████████| 342/342 [00:39<00:00,  8.57it/s] \n100%|██████████| 342/342 [00:17<00:00, 19.53it/s]\n100%|██████████| 152/152 [00:06<00:00, 23.97it/s]\nTraining MSE: 0.0142\nValidation MSE: 0.0817\nRunning time: 63.753881216049194\n\nEpoch 1 Loss: 0.0137 lr: 5e-05: 100%|██████████| 342/342 [00:45<00:00,  7.44it/s]\n100%|██████████| 342/342 [00:19<00:00, 17.98it/s]\n100%|██████████| 152/152 [00:07<00:00, 21.46it/s]\nTraining MSE: 0.0078\nValidation MSE: 0.0828\nRunning time: 72.11865544319153\n\nEpoch 1 Loss: 0.0113 lr: 5e-05: 100%|██████████| 342/342 [00:49<00:00,  6.86it/s]\n100%|██████████| 342/342 [00:20<00:00, 16.64it/s]\n100%|██████████| 152/152 [00:07<00:00, 19.54it/s]\nTraining MSE: 0.0063\nValidation MSE: 0.0786\nRunning time: 78.20980262756348\n\nEpoch 1 Loss: 0.0125 lr: 5e-05: 100%|██████████| 342/342 [00:57<00:00,  5.98it/s]\n100%|██████████| 342/342 [00:21<00:00, 15.58it/s]\n100%|██████████| 152/152 [00:08<00:00, 17.97it/s]\nTraining MSE: 0.0064\nValidation MSE: 0.0806\nRunning time: 87.63006591796875\n\nEpoch 1 Loss: 0.0104 lr: 5e-05: 100%|██████████| 342/342 [01:02<00:00,  5.44it/s]\n100%|██████████| 342/342 [00:23<00:00, 14.28it/s]\n100%|██████████| 152/152 [00:09<00:00, 16.55it/s]\nTraining MSE: 0.0085\nValidation MSE: 0.0836\nRunning time: 95.96596026420593\n\n[0.6929425500221427, 0.6986674181730343, 0.7005435001409075, 0.7030436007890817, 0.701864004186964, 0.6998188332863642]\n","output_type":"stream"}]},{"cell_type":"code","source":"#0-8 intermediate blocks and 4 layers \ntrain_error_n = []\nvali_error_n = []\nkt_error_5 = []\ntime_list_5 = []\nfor num_layers_to_keep in range(5):\n    model = MarkdownModel(deletelayers_layer_attention, num_layers_to_keep, 5)\n    model = model.cuda()\n    model, y_pred, train_MSE, vali_MSE, time_n = train(model, train_loader, val_loader, epochs=1)\n    train_error_n.append(train_MSE)\n    vali_error_n.append(vali_MSE)\n    time_list_5.append(time_n)\n    torch.save(model, 'codebert-trained2.pkl')\n    val_df[\"pred\"] = val_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)\n    val_df.loc[val_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_pred\n    y_dummy = val_df.sort_values(\"pred\").groupby('id')['cell_id'].apply(list)\n    kt_error_5.append(kendall_tau(df_orders.loc[y_dummy.index], y_dummy))\nprint(kt_error_5)","metadata":{"execution":{"iopub.status.busy":"2022-09-14T12:16:53.679559Z","iopub.execute_input":"2022-09-14T12:16:53.679954Z","iopub.status.idle":"2022-09-14T12:22:37.641698Z","shell.execute_reply.started":"2022-09-14T12:16:53.679917Z","shell.execute_reply":"2022-09-14T12:22:37.640430Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"Epoch 1 Loss: 0.052 lr: 5e-05: 100%|██████████| 342/342 [00:30<00:00, 11.30it/s] \n100%|██████████| 342/342 [00:16<00:00, 21.03it/s]\n100%|██████████| 152/152 [00:05<00:00, 26.34it/s]\nTraining MSE: 0.0376\nValidation MSE: 0.069\nRunning time: 52.32161903381348\n\nEpoch 1 Loss: 0.0178 lr: 5e-05: 100%|██████████| 342/342 [00:35<00:00,  9.55it/s]\n100%|██████████| 342/342 [00:19<00:00, 17.96it/s]\n100%|██████████| 152/152 [00:06<00:00, 24.54it/s]\nTraining MSE: 0.0079\nValidation MSE: 0.0787\nRunning time: 61.065041303634644\n\nEpoch 1 Loss: 0.0105 lr: 5e-05: 100%|██████████| 342/342 [00:42<00:00,  8.05it/s]\n100%|██████████| 342/342 [00:17<00:00, 19.17it/s]\n100%|██████████| 152/152 [00:06<00:00, 22.51it/s]\nTraining MSE: 0.0049\nValidation MSE: 0.074\nRunning time: 67.0911328792572\n\nEpoch 1 Loss: 0.0103 lr: 5e-05: 100%|██████████| 342/342 [00:47<00:00,  7.16it/s]\n100%|██████████| 342/342 [00:19<00:00, 17.46it/s]\n100%|██████████| 152/152 [00:07<00:00, 20.56it/s]\nTraining MSE: 0.0064\nValidation MSE: 0.0805\nRunning time: 74.79047083854675\n\nEpoch 1 Loss: 0.0091 lr: 5e-05: 100%|██████████| 342/342 [00:53<00:00,  6.34it/s]\n100%|██████████| 342/342 [00:20<00:00, 16.36it/s]\n100%|██████████| 152/152 [00:07<00:00, 19.23it/s]\nTraining MSE: 0.0063\nValidation MSE: 0.0823\nRunning time: 82.79995131492615\n\n[0.6962639397721325, 0.6999677925842425, 0.7078223761020975, 0.7033254156769596, 0.7037924232054431]\n","output_type":"stream"}]},{"cell_type":"code","source":"#0-8 intermediate blocks and 3 layers \ntrain_error_n = []\nvali_error_n = []\nkt_error_4 = []\ntime_list_4 = []\nfor num_layers_to_keep in range(4):\n    model = MarkdownModel(deletelayers_layer_attention, num_layers_to_keep, 4)\n    model = model.cuda()\n    model, y_pred, train_MSE, vali_MSE, time_n = train(model, train_loader, val_loader, epochs=1)\n    train_error_n.append(train_MSE)\n    vali_error_n.append(vali_MSE)\n    time_list_4.append(time_n)\n    torch.save(model, 'codebert-trained2.pkl')\n    val_df[\"pred\"] = val_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)\n    val_df.loc[val_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_pred\n    y_dummy = val_df.sort_values(\"pred\").groupby('id')['cell_id'].apply(list)\n    kt_error_4.append(kendall_tau(df_orders.loc[y_dummy.index], y_dummy))\nprint(kt_error_5)","metadata":{"execution":{"iopub.status.busy":"2022-09-14T12:25:07.445025Z","iopub.execute_input":"2022-09-14T12:25:07.445423Z","iopub.status.idle":"2022-09-14T12:29:05.313659Z","shell.execute_reply.started":"2022-09-14T12:25:07.445388Z","shell.execute_reply":"2022-09-14T12:29:05.312287Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"Epoch 1 Loss: 0.0513 lr: 5e-05: 100%|██████████| 342/342 [00:27<00:00, 12.65it/s]\n100%|██████████| 342/342 [00:15<00:00, 21.58it/s]\n100%|██████████| 152/152 [00:05<00:00, 26.91it/s]\nTraining MSE: 0.0373\nValidation MSE: 0.0745\nRunning time: 48.54228067398071\n\nEpoch 1 Loss: 0.0165 lr: 5e-05: 100%|██████████| 342/342 [00:32<00:00, 10.56it/s]\n100%|██████████| 342/342 [00:16<00:00, 21.27it/s]\n100%|██████████| 152/152 [00:06<00:00, 23.74it/s]\nTraining MSE: 0.0075\nValidation MSE: 0.0807\nRunning time: 54.86864995956421\n\nEpoch 1 Loss: 0.0103 lr: 5e-05: 100%|██████████| 342/342 [00:37<00:00,  9.15it/s]\n100%|██████████| 342/342 [00:17<00:00, 19.96it/s]\n100%|██████████| 152/152 [00:06<00:00, 23.13it/s]\nTraining MSE: 0.0062\nValidation MSE: 0.0792\nRunning time: 61.11457133293152\n\nEpoch 1 Loss: 0.0084 lr: 5e-05: 100%|██████████| 342/342 [00:43<00:00,  7.94it/s]\n100%|██████████| 342/342 [00:18<00:00, 18.30it/s]\n100%|██████████| 152/152 [00:06<00:00, 22.24it/s]\nTraining MSE: 0.0043\nValidation MSE: 0.075\nRunning time: 68.61215925216675\n\n[0.6962639397721325, 0.6999677925842425, 0.7078223761020975, 0.7033254156769596, 0.7037924232054431]\n","output_type":"stream"}]},{"cell_type":"code","source":"#Plot the chart about the different numbers of intermediate blocks with 8 Encoder Layers vs Kendall Tau Correlation\nfig, ax = plt.subplots()\nx = np.arange(2,8,1)\nax.plot(kt_error_n, label='7 Encoder Layers')\nax.plot(kt_error_7, label='6 Encoder Layers')\nax.plot(kt_error_6, label='5 Encoder Layers')\nax.plot(kt_error_5, label='4 Encoder Layers')\nax.plot(kt_error_4, label='3 Encoder Layers')\n#plt.xlim(2,7)\nplt.xlabel('the Numbers of Intermediate Blocks')\nplt.ylabel('Kendall Tau Correlation Values')\nax.legend()","metadata":{"execution":{"iopub.status.busy":"2022-09-14T12:29:45.148478Z","iopub.execute_input":"2022-09-14T12:29:45.149018Z","iopub.status.idle":"2022-09-14T12:29:45.453349Z","shell.execute_reply.started":"2022-09-14T12:29:45.148983Z","shell.execute_reply":"2022-09-14T12:29:45.452313Z"},"trusted":true},"execution_count":59,"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"<matplotlib.legend.Legend at 0x7f203f85f150>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"#Get errors of the different numbers of intermediate blocks with 12 encoder layers\ntrain_error = []\nvali_error = []\nkt_error = []\ntime_list = []\nfor num_layers_to_keep in range(13):\n    #mstart = torch.cuda.memory_allocated(torch.cuda.current_device())\n    model = MarkdownModel(deletelayers, num_layers_to_keep,0)\n    model = model.cuda()\n    model, y_pred, train_MSE, vali_MSE, time_n = train(model, train_loader, val_loader, epochs=1)\n    train_error.append(train_MSE)\n    vali_error.append(vali_MSE)\n    time_list.append(time_n)\n    torch.save(model, 'codebert-trained2.pkl')\n    val_df[\"pred\"] = val_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)\n    val_df.loc[val_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_pred\n    y_dummy = val_df.sort_values(\"pred\").groupby('id')['cell_id'].apply(list)\n    kt_error.append(kendall_tau(df_orders.loc[y_dummy.index], y_dummy))\n    #mend = torch.cuda.memory_allocated(torch.cuda.current_device())\n    print(\"torch.cuda.memory_allocated: %fKB\"%(torch.cuda.memory_allocated(0)))\n    print(\"torch.cuda.memory_reserved: %fKB\"%(torch.cuda.memory_reserved(0)))\n    print(\"torch.cuda.max_memory_reserved: %fKB\"%(torch.cuda.max_memory_reserved(0)))\n    \n#print(np.mean(train_error)) \n#print(np.mean(vali_error))","metadata":{"execution":{"iopub.status.busy":"2022-09-14T11:20:37.759420Z","iopub.status.idle":"2022-09-14T11:20:37.760161Z","shell.execute_reply.started":"2022-09-14T11:20:37.759907Z","shell.execute_reply":"2022-09-14T11:20:37.759932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Get the time decrese for the different numbers of intermediate blocks with 12 encoder layers\nt_ans = []\nfor i in range(13):\n    t_ans.append((time_list[12] - time_list[i]) / time_list[12])\nt_ans","metadata":{"execution":{"iopub.status.busy":"2022-09-14T11:20:37.761430Z","iopub.status.idle":"2022-09-14T11:20:37.762193Z","shell.execute_reply.started":"2022-09-14T11:20:37.761938Z","shell.execute_reply":"2022-09-14T11:20:37.761962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Get the size decrese for the different numbers of intermediate blocks with 12 encoder layers\nsi_ans = []\nsize_i = [67.37,72.09,76.81,81.54,86.26,90.99,95.71,100.43,105.16,109.88,114.61,119.33,124.05]\nfor i in range(12,-1,-1):\n    si_ans.append((size_i[12] - size_i[i]) / size_i[12])\nsi_ans","metadata":{"execution":{"iopub.status.busy":"2022-09-14T11:20:37.763490Z","iopub.status.idle":"2022-09-14T11:20:37.764221Z","shell.execute_reply.started":"2022-09-14T11:20:37.763964Z","shell.execute_reply":"2022-09-14T11:20:37.763988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots() \nx = np.arange(0,13,1)\nax.plot(kt_error, label='Kendall Tau Correlation')\nax.plot(t_ans, label='Running Time Increase')\nax.plot(si_ans, label='Size Decrease')\nax.legend(loc='upper left')\nplt.xlabel('the Numbers of Intermediate Blocks')\nplt.ylabel('Values')","metadata":{"execution":{"iopub.status.busy":"2022-09-14T11:20:37.765490Z","iopub.status.idle":"2022-09-14T11:20:37.766218Z","shell.execute_reply.started":"2022-09-14T11:20:37.765971Z","shell.execute_reply":"2022-09-14T11:20:37.765995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##Get errors of the different numbers of encoder layers\ntrain_error_l = []\nvali_error_l = []\nkt_error_l = []\ntime_list_l = []\nfor num_layers_to_keep in range(1,13):\n    model = MarkdownModel(deletelayers_layer, num_layers_to_keep,12)\n    model = model.cuda()\n    model, y_pred, train_MSE, vali_MSE, time_n = train(model, train_loader, val_loader, epochs=1)\n    train_error_l.append(train_MSE)\n    vali_error_l.append(vali_MSE)\n    time_list_l.append(time_n)\n    torch.save(model, 'codebert-trained2.pkl')\n    val_df[\"pred\"] = val_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)\n    val_df.loc[val_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_pred\n    y_dummy = val_df.sort_values(\"pred\").groupby('id')['cell_id'].apply(list)\n    kt_error_l.append(kendall_tau(df_orders.loc[y_dummy.index], y_dummy))","metadata":{"execution":{"iopub.status.busy":"2022-09-14T11:20:37.767578Z","iopub.status.idle":"2022-09-14T11:20:37.768303Z","shell.execute_reply.started":"2022-09-14T11:20:37.768046Z","shell.execute_reply":"2022-09-14T11:20:37.768070Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots() \nx = np.linspace(0,13) \nax.plot(kt_error_a)\nax.legend(loc='upper left')\nplt.xlabel('the Numbers of Self-attention Blocks')\nplt.ylabel('Kendall Tau Correlation')","metadata":{"execution":{"iopub.status.busy":"2022-09-14T11:20:37.769596Z","iopub.status.idle":"2022-09-14T11:20:37.770321Z","shell.execute_reply.started":"2022-09-14T11:20:37.770063Z","shell.execute_reply":"2022-09-14T11:20:37.770087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots()\ny1 = kt_error_l\nax.plot( y1, label='linear') ","metadata":{"execution":{"iopub.status.busy":"2022-09-14T11:20:37.771608Z","iopub.status.idle":"2022-09-14T11:20:37.772341Z","shell.execute_reply.started":"2022-09-14T11:20:37.772075Z","shell.execute_reply":"2022-09-14T11:20:37.772099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Get the time decrease for the different numbers of encoder layers\ntime_l_d = []\nfor i in range(13):\n    time_l_d.append(round(time_list_l[12]/time_list_l[i],2))\ntime_l_d","metadata":{"execution":{"iopub.status.busy":"2022-09-14T11:20:37.775048Z","iopub.status.idle":"2022-09-14T11:20:37.776303Z","shell.execute_reply.started":"2022-09-14T11:20:37.776012Z","shell.execute_reply":"2022-09-14T11:20:37.776040Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}